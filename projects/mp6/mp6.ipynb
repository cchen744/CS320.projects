{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4363f7e0-a654-4df1-ad89-67a1fff8825c",
   "metadata": {},
   "source": [
    "# Machine Project 6: EDGAR Web Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a0df377-dab6-4220-8ba1-5137b4c7782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Add imports used throughout the project here\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285c3e5-e9ed-411f-8e11-fb5aa4c6db76",
   "metadata": {},
   "source": [
    "# Group Part (75%)\n",
    "\n",
    "For this portion of the machine project, you may collaborate with your group members in any way (including looking at group members' code). You may also seek help from CS 320 course staff (peer mentors, TAs, and the instructor). You **may not** seek or receive help from other CS 320 students (outside of your group) or anybody else outside of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e94aa2-409d-49bd-9452-315d25a06bff",
   "metadata": {},
   "source": [
    "## Part 1: `server_log.zip` analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44364298-db8e-4f14-b039-3aa9bedbfd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>zone</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>extention</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>idx</th>\n",
       "      <th>norefer</th>\n",
       "      <th>noagent</th>\n",
       "      <th>find</th>\n",
       "      <th>crawler</th>\n",
       "      <th>browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104.197.32.ihd</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1111711.0</td>\n",
       "      <td>0001193125-12-324016</td>\n",
       "      <td>-index.htm</td>\n",
       "      <td>200.0</td>\n",
       "      <td>7627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208.77.214.jeh</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>789019.0</td>\n",
       "      <td>0001193125-06-031505</td>\n",
       "      <td>.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>46327.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.197.228.dbe</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800166.0</td>\n",
       "      <td>0001279569-16-003038</td>\n",
       "      <td>-index.htm</td>\n",
       "      <td>200.0</td>\n",
       "      <td>16414.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108.39.205.jga</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354950.0</td>\n",
       "      <td>0000950123-09-011236</td>\n",
       "      <td>-index.htm</td>\n",
       "      <td>200.0</td>\n",
       "      <td>8718.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.45.218.ihf</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1313918.0</td>\n",
       "      <td>0001209191-06-031555</td>\n",
       "      <td>.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>8911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ip        date      time  zone        cik  \\\n",
       "0  104.197.32.ihd  2017-01-01  00:00:00   0.0  1111711.0   \n",
       "1  208.77.214.jeh  2017-01-01  00:00:00   0.0   789019.0   \n",
       "2  54.197.228.dbe  2017-01-01  00:00:00   0.0   800166.0   \n",
       "3  108.39.205.jga  2017-01-01  00:00:01   0.0   354950.0   \n",
       "4   52.45.218.ihf  2017-01-01  00:00:01   0.0  1313918.0   \n",
       "\n",
       "              accession   extention   code     size  idx  norefer  noagent  \\\n",
       "0  0001193125-12-324016  -index.htm  200.0   7627.0  1.0      0.0      0.0   \n",
       "1  0001193125-06-031505        .txt  200.0  46327.0  0.0      0.0      0.0   \n",
       "2  0001279569-16-003038  -index.htm  200.0  16414.0  1.0      0.0      0.0   \n",
       "3  0000950123-09-011236  -index.htm  200.0   8718.0  1.0      0.0      0.0   \n",
       "4  0001209191-06-031555        .txt  200.0   8911.0  0.0      0.0      0.0   \n",
       "\n",
       "   find  crawler  browser  \n",
       "0  10.0      0.0      NaN  \n",
       "1  10.0      0.0      NaN  \n",
       "2  10.0      0.0      NaN  \n",
       "3  10.0      0.0      NaN  \n",
       "4  10.0      0.0      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pandas to read in \"server_log.zip as a csv file\"\n",
    "server_log = pd.read_csv(\"server_log.zip\",compression = 'zip')\n",
    "server_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158789f6-e360-476f-b9da-0c29864c6e88",
   "metadata": {},
   "source": [
    "### Q1: What's the total size in bytes of the files requested?\n",
    "\n",
    "Look at the `size` column of the CSV in `server_log.zip`.  We want to include duplicates here; this gives us an estimate of the amount of network traffic handled by EDGAR (since this data is only a sample, the true value will be even larger). Answer with an integer. \n",
    "\n",
    "**Note:** If you use `numpy` make sure to cast the final answer to an `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e069fd-1aeb-4e7c-ba6b-747562ecbed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24801002666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1\n",
    "int(server_log['size'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb264a-8b2d-4530-a8a0-ee536b051d9e",
   "metadata": {},
   "source": [
    "### Q2: How many filings have been accessed by the 10 IPs with the most accesses?\n",
    "\n",
    "Answer with a dictionary, with the (anonymized) IP as key and the number of requests seen in the logs as the values. Each row in the logs corresponds to one request. Note that the anonymized IP addresses are consistent between requests.\n",
    "\n",
    "**Hint:** for this question and most of the others expecting dictionary output, it might be easiest to use Pandas operations to process the data into a `Series` and to use the `to_dict()` method. Consider using tools like `groupby`, `apply`, and aggregation methods like `size()`. In Q30-32 from [MP1](../mp1/README.md), there is an example of `apply`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09b960e-7ba4-46a1-86e4-ab2ecaf46e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'54.152.17.ccg': 12562,\n",
       " '183.195.251.hah': 6524,\n",
       " '52.45.218.ihf': 5562,\n",
       " '68.180.231.abf': 5493,\n",
       " '204.212.175.bch': 4708,\n",
       " '103.238.106.gif': 4428,\n",
       " '208.77.215.jeh': 3903,\n",
       " '208.77.214.jeh': 3806,\n",
       " '217.174.255.dgd': 3551,\n",
       " '82.13.163.caf': 3527}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2\n",
    "server_log['ip'].value_counts()[:10].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f4d4e-b493-4022-aef4-949bf1ff6434",
   "metadata": {},
   "source": [
    "### Q3: What fraction of the requests had errors?\n",
    "\n",
    "Any request with a status code greater than or equal to 400 has an error. Answer with a floating point number. \n",
    "\n",
    "**Note:** If you use `numpy` make sure to cast the final answer to a `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6c5b24-eca4-41db-a662-6d58b4b1ab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03466852724527611"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3\n",
    "float((server_log['code']>=400).sum()/len(server_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31ca2d-e565-4fd9-aa15-db8de1c11f56",
   "metadata": {},
   "source": [
    "### Q4: What is the second most frequently accessed file?\n",
    "\n",
    "Answer with a string formatted like so: \"cik/accession/extention\" (these are the names of columns in \"rows.csv\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c8d99df-7357-4df0-a490-eac1f7edf4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1584509/0001584509-16-000514/armk-20160930_def.xml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4\n",
    "server_log_q4 = server_log\n",
    "server_log_q4['cik'] = server_log['cik'].astype(int)\n",
    "server_log_q4['file_name'] = server_log_q4[['cik','accession','extention']].astype(str).agg('/'.join, axis=1)\n",
    "server_log_q4['file_name'].value_counts().index[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508d262-ab1f-473d-b85b-e78141369fe5",
   "metadata": {},
   "source": [
    "## Part 2: Creating `edgar_utils.py` module\n",
    "\n",
    "This part is to be started during [Lab 9](../../labs/Lab9/README.md). Finish the `edgar_utils.py` module now if you didn't have enough time\n",
    "during the scheduled lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3cd5f6-76b2-4329-b0db-d62dadd4227b",
   "metadata": {},
   "source": [
    "## Part 3: Using `edgar_utils.py` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ebd47b-e0e1-4d4c-a34c-52bacf5a3ae5",
   "metadata": {},
   "source": [
    "### Q5: Which region accesses resources most heavily in `server_log.zip`?\n",
    "\n",
    "Use your `lookup_region` function and answer with a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6259e08d-c826-4f67-ad81-0df6410b9a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States of America'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5\n",
    "import edgar_utils\n",
    "server_log['region'] = server_log['ip'].apply(edgar_utils.lookup_region)\n",
    "server_log['region'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f54855-ae79-46f5-b52f-ed0816cffe1a",
   "metadata": {},
   "source": [
    "### Q6: What fraction of IPs in each region are high-volume users?\n",
    "\n",
    "Consider IPs which accessed more than 300 EDGAR resoures to be\n",
    "high-volume. This might indicate machines running automated scraping\n",
    "and analysis tasks.\n",
    "\n",
    "Note that given the sampling done in the data, the true EDGAR usage of\n",
    "these machines is likely to be even heavier.\n",
    "\n",
    "Answer with a dictionary, where the keys are the regions and the\n",
    "values are the fraction (in floating point form) of IPs from that\n",
    "region classified as high-volume.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Say \"United States of America\" has four IPs:\n",
    "* 1.1.1.1 appears 1200 times in the logs\n",
    "* 2.2.2.2 appears 900 times in the logs\n",
    "* 3.3.3.3 appears 5 times in the logs\n",
    "* 4.4.4.4 appears 234 times in the logs\n",
    "\n",
    "This means that 1/2 of the IPs in the US are high volume, so there should be an entry like this:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"United States of America\": 0.5,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "**Note:** Some of the filings are listed as having a region of '-'. Please include this in your final\n",
    "answer.\n",
    "\n",
    "**Note:** If you use `numpy` make sure to cast dictionary entries to `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aad5538-a98a-4055-a29d-b89f3acd1b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Canada': 0.05357142857142857,\n",
       " 'Luxembourg': 0.0,\n",
       " 'North Macedonia': 0.0,\n",
       " 'Finland': 0.0,\n",
       " 'Mexico': 0.0,\n",
       " 'Israel': 0.0,\n",
       " 'Lebanon': 0.0,\n",
       " 'Hungary': 0.0,\n",
       " 'Honduras': 0.0,\n",
       " 'Bangladesh': 0.0,\n",
       " 'Turkey': 0.0,\n",
       " 'Viet Nam': 0.0,\n",
       " 'Sweden': 0.0,\n",
       " '-': 0.0,\n",
       " 'Virgin Islands (British)': 0.0,\n",
       " 'Ukraine': 0.0,\n",
       " 'Cyprus': 0.0,\n",
       " 'Greece': 0.0,\n",
       " 'India': 0.08823529411764706,\n",
       " 'Hong Kong': 0.037037037037037035,\n",
       " 'Pakistan': 0.0,\n",
       " 'Poland': 0.0,\n",
       " 'United States of America': 0.04889228418640183,\n",
       " 'Austria': 0.0,\n",
       " 'Indonesia': 0.0,\n",
       " 'Netherlands': 0.0,\n",
       " 'Egypt': 0.0,\n",
       " 'Slovenia': 0.0,\n",
       " 'Syrian Arab Republic': 0.0,\n",
       " 'Angola': 0.0,\n",
       " 'Russian Federation': 0.0,\n",
       " 'Portugal': 0.0,\n",
       " 'Latvia': 0.0,\n",
       " 'Estonia': 0.0,\n",
       " 'Romania': 0.0,\n",
       " 'Malaysia': 0.0,\n",
       " 'Jordan': 0.0,\n",
       " 'France': 0.0036900369003690036,\n",
       " 'Spain': 0.0,\n",
       " 'Slovakia': 0.0,\n",
       " 'South Africa': 0.0,\n",
       " 'Ireland': 0.625,\n",
       " 'Sudan': 0.0,\n",
       " 'Germany': 0.047619047619047616,\n",
       " 'Algeria': 0.0,\n",
       " 'Czechia': 0.3333333333333333,\n",
       " 'Australia': 0.07692307692307693,\n",
       " 'Japan': 0.0,\n",
       " 'Jersey': 0.0,\n",
       " 'Taiwan (Province of China)': 0.0,\n",
       " 'Nigeria': 0.0,\n",
       " 'Bulgaria': 0.3333333333333333,\n",
       " 'Mongolia': 0.0,\n",
       " 'Yemen': 0.0,\n",
       " 'Morocco': 0.0,\n",
       " 'Saudi Arabia': 0.0,\n",
       " 'Iraq': 0.0,\n",
       " 'United Kingdom of Great Britain and Northern Ireland': 0.08888888888888889,\n",
       " 'Italy': 0.0,\n",
       " 'Croatia': 0.0,\n",
       " 'Liberia': 0.0,\n",
       " 'Singapore': 0.0,\n",
       " 'Philippines': 0.0,\n",
       " 'Venezuela (Bolivarian Republic of)': 0.0,\n",
       " 'Korea (Republic of)': 0.2,\n",
       " 'Thailand': 0.0,\n",
       " 'Brazil': 0.0,\n",
       " 'Tanzania, United Republic of': 0.0,\n",
       " 'Switzerland': 0.0,\n",
       " 'Armenia': 0.0,\n",
       " 'China': 0.016018306636155607,\n",
       " 'Denmark': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6\n",
    "regions = set(server_log['region'])\n",
    "frac_hcol = {region:0 for region in regions}\n",
    "for region in frac_hcol:\n",
    "    ips_of_this_region = server_log[server_log['region']==region]['ip']\n",
    "    frac_hcol_of_this_region = float((ips_of_this_region.value_counts()>300).mean())\n",
    "    frac_hcol[region] = frac_hcol_of_this_region\n",
    "frac_hcol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed59a7-99e8-464a-bd63-c950a31b7b5c",
   "metadata": {},
   "source": [
    "### Requirement: `filings` dictionary\n",
    "\n",
    "Read every file ending with .htm or .html in `docs.zip`, and create a `Filing`\n",
    "object based on that file. Then, save that `Filing` object to a dictionary as follows:\n",
    "- **Key:** The filepath for this filing object (ex. `850693/0000850693-07-000159/-index.htm`)\n",
    "- **Value:** The `Filing` object created from this filepath.\n",
    "\n",
    "Creating this dictionary once now will save us from needing to loop over all values\n",
    "in future questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ab834c-ef6b-43ec-acc2-e45ad7920937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `filings` dictionary\n",
    "filings = {}\n",
    "with zipfile.ZipFile('docs.zip','r') as folder:\n",
    "    for file in folder.namelist():\n",
    "        if file.endswith(('html','htm')):\n",
    "            with folder.open(file) as f:\n",
    "                html_content = f.read().decode('utf-8') \n",
    "                filing_obj = edgar_utils.Filing(html_content)\n",
    "                filings[file] = filing_obj\n",
    "# filings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f28cd-e6b2-44aa-a498-d428222b4006",
   "metadata": {},
   "source": [
    "### Q7: What dates appear in the `886982/0000769993-16-001958/-index.htm` file of `docs.zip`?\n",
    "\n",
    "Read the HTML from this file and use it to create a `Filing` object,\n",
    "from which you can access the `.dates` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50efdb1f-271e-4136-903a-0bf635a76eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-12-30', '2016-12-30', '2016-12-20']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7\n",
    "filings['886982/0000769993-16-001958/-index.htm'].dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ef0d1-757b-478a-ab71-03e03d6e8abb",
   "metadata": {},
   "source": [
    "### Q8: What is the distribution of states for the filings in `docs.zip`?\n",
    "\n",
    "Answer with a dict, like the following:\n",
    "\n",
    "```\n",
    "{'CA': 92,\n",
    " 'NY': 83,\n",
    " 'TX': 67,\n",
    " 'None': 56,\n",
    " 'MA': 30,\n",
    " 'IL': 25,\n",
    " 'PA': 25,\n",
    " 'CO': 25,\n",
    " ...\n",
    "}\n",
    "```\n",
    "\n",
    "The showing order of each key-value pair doesn't really matter. Please include `None` in the\n",
    "dictionary.\n",
    "\n",
    "**Hint:** We created the `filings` dictionary above, which means we don't have to\n",
    "iterate through `docs.zip` here again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c19918-1879-48c9-862e-a80c4d4b2384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OX': 13,\n",
       " 'CA': 707,\n",
       " 'NJ': 69,\n",
       " 'MS': 7,\n",
       " 'MA': 91,\n",
       " 'CO': 62,\n",
       " 'NY': 351,\n",
       " 'TX': 194,\n",
       " 'FL': 55,\n",
       " 'AL': 2,\n",
       " 'IN': 15,\n",
       " 'CT': 150,\n",
       " 'UT': 14,\n",
       " 'NV': 25,\n",
       " 'MD': 25,\n",
       " 'KS': 12,\n",
       " 'MO': 11,\n",
       " 'VA': 38,\n",
       " 'OH': 22,\n",
       " 'WA': 12,\n",
       " 'SD': 3,\n",
       " 'DE': 38,\n",
       " 'GA': 106,\n",
       " 'IL': 91,\n",
       " 'NC': 34,\n",
       " 'PA': 61,\n",
       " 'TN': 7,\n",
       " 'MN': 34,\n",
       " 'NM': 2,\n",
       " 'KY': 4,\n",
       " 'OK': 15,\n",
       " 'AR': 5,\n",
       " 'LA': 12,\n",
       " 'VT': 2,\n",
       " 'MI': 25,\n",
       " 'NE': 9,\n",
       " 'IA': 16,\n",
       " 'AZ': 15,\n",
       " 'WI': 25,\n",
       " 'OR': 6,\n",
       " 'ID': 2,\n",
       " 'WV': 4,\n",
       " 'DC': 2,\n",
       " 'ME': 2}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8\n",
    "state_counts = {}\n",
    "all_states = []\n",
    "for item in filings:\n",
    "    all_states.extend([''.join(re.findall(r'[A-Z]{2}',zipcode)) for zipcode in filings[item].state()])\n",
    "\n",
    "for state in all_states:\n",
    "    if state not in state_counts:\n",
    "        state_counts[state]=1\n",
    "    else:\n",
    "        state_counts[state]+=1\n",
    "state_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec61c9-8a25-48f2-9e24-f36cec919fa6",
   "metadata": {},
   "source": [
    "### Q9: What is the distribution for the ten most common addresses for the filings in `docs.zip`?\n",
    "\n",
    "Answer in the same format as the previous question.\n",
    "\n",
    "Expected output:\n",
    "```\n",
    "{'2000 AVENUE OF THE STARS, 12TH FLOOR\\nLOS ANGELES CA 90067': 134,\n",
    " '2000 AVENUE OF THE STARS, 12TH FLOOR\\nLOS ANGELES CA 90067\\n3102014100': 113,\n",
    " '3 LANDMARK SQUARE\\nSUITE 500\\nSTAMFORD CT 06901\\n2033564400': 60,\n",
    " 'C/O KKR ASSET MANAGEMENT LLC\\n555 CALIFORNIA STREET, 50TH FLOOR\\nSAN FRANCISCO CA 94104': 36,\n",
    " 'C/O ARES MANAGEMENT LLC\\n2000 AVENUE OF THE STARS, 12TH FLOOR\\nLOS ANGELES CA 90067': 35,\n",
    " '4740 AGAR DRIVE\\nRICHMOND A1 V7B 1A3': 25,\n",
    " 'CENTRALIS S.A., 8-10 AVENUE DE LA GARE\\nLUXEMBOURG N4 L-1610': 25,\n",
    " 'CENTRALIS S.A., 8-10 AVENUE DE LA GARE\\nLUXEMBOURG N4 L-1610\\n352-26-186-1': 25,\n",
    " '3 LANDMARK SQUARE\\nSUITE 500\\nSTAMFORD CT 06901': 24,\n",
    " '801 CHERRY STREET\\nSUITE 2100\\nFORT WORTH TX 76102': 22}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb2932-6e96-4747-ba84-09b795be5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ed8ab-a980-4040-8e74-bfbf853ed378",
   "metadata": {},
   "source": [
    "# Individual Part (25%)\n",
    "\n",
    "For this portion of the machine project, you are only allowed to seek help from CS 320 course staff (peer mentors, TAs, and the instructor). You **may not** receive help from anyone else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d94198-5f35-4463-accd-8170062b3c86",
   "metadata": {},
   "source": [
    "## Part 4: Combining logs with documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07046cb-3f50-4dca-ac32-03be88e0b607",
   "metadata": {},
   "source": [
    "### Q10: What is the distribution of requests across industries?\n",
    "\n",
    "For each request in the logs that has a corresponding filing in\n",
    "`docs.zip`, lookup the SIC (ignore rows in the logs which refer to\n",
    "pages not in `docs.zip`).\n",
    "\n",
    "Answer with a dictionary, where the keys are the SIC and the values\n",
    "are the number of times the resources of that industry were accessed.\n",
    "\n",
    "If you're curious, consider looking up the industry names for the top\n",
    "couple categories:\n",
    "https://www.sec.gov/corpfin/division-of-corporation-finance-standard-industrial-classification-sic-code-list\n",
    "\n",
    "Expected output:\n",
    "\n",
    "```\n",
    "{2834: 984,\n",
    " 1389: 656,\n",
    " 1311: 550,\n",
    " 2836: 429,\n",
    " 6022: 379,\n",
    " 1000: 273,\n",
    " ...\n",
    " }\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5d2ab-5a12-439a-a31a-5165dc0fc34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb925c-737d-40c7-8a6d-6784d55afffb",
   "metadata": {},
   "source": [
    "\n",
    "### Q11: How many requests were made in each hour?\n",
    "\n",
    "Use `pd.to_datetime` (the `hour` attributes of the converted\n",
    "timestamps may be useful) or string manipulation to process the `time`\n",
    "column. Answer with a dictionary, where the keys are integers from 0\n",
    "to 23 representing the hour of the day, and the values are the number\n",
    "of requests made in that hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904c452-b3b0-45dd-b85b-715e964ae766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35944626-abbf-4ebb-bf48-5d923d57d857",
   "metadata": {},
   "source": [
    "### Q12: What is the geographic overlap in interest between Australia, France, Indonesia, and Viet Nam?\n",
    "\n",
    "Answer with a Digraph like the following:\n",
    "\n",
    "<img src=\"img/digraph.png\" width=400>\n",
    "\n",
    "In addition to a node for each of these three countries, there should\n",
    "be a node for each state having a filing accessed by somebody in one\n",
    "of these countries.\n",
    "\n",
    "An edge from a country to a state means somebody in that country\n",
    "looked at least one filing for a company in that state.\n",
    "\n",
    "**Important:** Make sure not to hardcode these values. It might be helpful to\n",
    "define a list like `countries = [\"Australia\", \"France\", \"Indonesia\", \"Viet Nam\"]` and then loop over the filings for these countries only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b83e9-c913-48c5-8003-aa366a40a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q12\n",
    "d = graphviz.Digraph()\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "# IMPORTANT -- Do not remove -- \n",
    "with open(\"Q12.pkl\", \"wb\") as f:\n",
    "    pickle.dump(d.source, f)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3ae7c-28cf-44a7-8c2e-4f35e7561604",
   "metadata": {},
   "source": [
    "### Q13: Geographic plotting of postal code\n",
    "\n",
    "The `locations.geojson` contains the positions of some of the\n",
    "addresses in the dataset.  Plot this over the background map in\n",
    "\"shapes/cb_2018_us_state_20m.shp\"\n",
    "\n",
    "Additional requirements:\n",
    "\n",
    "* **Important:** Make sure to pass in `ax` as an argument when plotting: `.plot(ax=ax, ...)`\n",
    "* Use the given lat/lon to crop the bounds:\n",
    "* Use a Mercator projection, \"epsg:2022\"\n",
    "* The color of each point should indicate the postal code. For example, the postal code of `245 SUMMER STREET\\nBOSTON MA 02210` is `2210`. If it's in the form like `53705-1234`, only take `53705`. If it's neither 5 digits number nor 9 digits number, don't use the point.\n",
    "* Only show the street with a postal code from 10000 to 60000\n",
    "* Use the \"viridis\" colormap, with a colorbar\n",
    "* The color of background is \"lightgray\"\n",
    "\n",
    "The result should look similar to this:\n",
    "\n",
    "<img src=\"img/geo.png\" width=\"400px\">\n",
    "\n",
    "**Hint:** If you are getting issues with getting the slanted lines or issues with your graphs \n",
    "disappearing, make sure that you are applying the `.to_crs(...)` function to both the points\n",
    "and the background before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e3db0-1c1c-48af-9b39-5431cf9ee857",
   "metadata": {},
   "outputs": [],
   "source": [
    "west = -90\n",
    "east = -65\n",
    "north = 50\n",
    "south = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266c11c-2bc9-4882-943d-92dcb280fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q13\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# PLOT HERE\n",
    "\n",
    "# IMPORTANT -- Do not remove -- \n",
    "with open(\"Q13.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fig, f)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
